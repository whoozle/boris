#!/usr/bin/env python

import argparse
import os
import os.path
import re
import sys

class Patcher(object):
	def replace_lines(self, path, data, line, match, replacement):
		print "replacing line ", line
		pass

class Tokenizer(object):
	spacer = re.compile(r'\s+')
	nl = re.compile(r'\n')

	def __init__(self, patch, path, data, tab_size):
		self.__patch = patch
		self.__path = path
		self.__data = Tokenizer.nl.split(data)
		self.__tab = tab_size
		self.__map = []

	def get_visual_size(self, line):
		tabs = line.count('\t')
		return len(line) + tabs * (self.__tab - 1)

	def scan_line(self, lineno, offset, vs_offset):
		line = self.__data[lineno]
		vp = 0
		line_len = len(line)
		for idx in xrange(0, line_len):
			if line[idx] == '\t':
				vs_offset -= self.__tab
			else:
				vs_offset -= 1

			if vs_offset < 0:
				return False
			elif vs_offset == 0:
				return idx + 1 == offset

	def scan_context(self, lineno, offset, vs_offset):
		begin, end = lineno, lineno

		while begin > 0:
			if not self.scan_line(begin, offset, vs_offset):
				break
			begin -= 1

		while end < len(self.__data):
			end += 1
			if not self.scan_line(end, offset, vs_offset):
				break

		return begin, end

	def process_match(self, lineno, replacement, match):
		begin, end = match.start(), match.end()
		line = self.__data[lineno]
		prefix, suffix = line[:begin], line[end:]
		next_align = Tokenizer.spacer.match(suffix)
		replacement = prefix + replacement + suffix
		if not next_align:
			self.__patch.replace_lines(self.__path, self.__data, lineno, match, replacement)
			return

		offset = end + next_align.end()
		vs_offset = self.get_visual_size(line[:offset])
		line1, line2 = self.scan_context(lineno, offset, vs_offset)
		self.__patch.replace_lines(self.__path, self.__data, (line1, line2), match, replacement)

	def replace(self, old, new):
		for lineno in xrange(0, len(self.__data)):
			line = self.__data[lineno]
			for match in old.finditer(line):
				self.process_match(lineno, new, match)

class Boris(object):
	def __init__(self, args):
		self.args = args
		self.tab_size = args.tab
		self.__patch = Patcher()
		self.__filter = set([('.' + x if x[0] != '.' else x) for x in args.filter.split(',')])
		self.__old = re.compile(args.old)
		self.__new = args.new #fixme: replace groups here

	def process_file(self, path):
		_p, ext = os.path.splitext(path)
		if self.__filter and ext not in self.__filter:
			return

		with open(path) as fd:
			data = fd.read()

		tok = Tokenizer(self.__patch, path, data, self.tab_size)
		tok.replace(self.__old, self.__new)

	def process_path(self, path):
		if not os.path.exists(path):
			raise OSError(2, 'No such file or directory', path)
		if os.path.isfile(path):
			self.process_file(path)
		else:
			for root, dirs, files in os.walk(path):
				for file in files:
					self.process_file(os.path.join(root, file))

parser = argparse.ArgumentParser(description='Mass replace indent-saving tool')
parser.add_argument('old', help='old pattern')
parser.add_argument('new', help='new pattern')
parser.add_argument('path', help='files/directories to replace', nargs=1)
parser.add_argument('-t', '--tab-size', help='tab size, default 4', dest='tab', type=int, default=4)
parser.add_argument('-e', '--extensions', dest='filter')

args = parser.parse_args()

rpl = Boris(args)

for path in args.path:
	rpl.process_path(path)
